---
title: "Semana 30: Búsqueda de librerías para detectar personas en vídeo."
categories:
  - Weblog
tags:
  - CUDA
  - C++ to Python
---
 
---

He conseguido obtener una librería bien organizada que use Yolo para detectar personas que funcione en python, que sea un código más o menos actual y que no tenga mil dependencias. Parece que ha sido fácil pero primero he intentado todas estas librerías.

Lo primero que probé es modificando el driver de ROS2 Foxy de DarknetROS que hizo un tipo que tiene un pull request abierto desde hace mucho a ROS2 Humble. Pero al final la idea del ejercicio es que el alumno también haga la parte perceptiva, y eso venía todo dado en el paquete que edité. Y no se podía usar ya que Unibotics está pensado para usarse en Python y estaba escrito en C++.

Luego usé esta: https://github.com/jahongir7174/YOLOv8-human
Esta librería es otra librería que estaba bastante bien, pero no me gustaba su organización así que la dejé como segunda opción.

Luego esta: https://github.com/mkocabas/yolov3-pytorch
Esta tenía problemas de dependecias de paquetes muy antiguos que no tiene sentido usar si se quiere algo robusto y que se mantenga en el tiempo.

https://github.com/CAMMA-public/MVOR
Esta librería se excedía de la complejidad que buscaba, ya que detectaba keypoint de personas, estimaba su posición en 3D y demás.

https://github.com/pushprajkatiyar/person_detection_from_cctv_video
Tambíen, librería muy antigua que tenía errores de versión de independecias infinitos.

https://github.com/vinay0410/Pedestrian_Detection
Esta librería iba extrañamente lenta y mal, así que la deseché porque iba más o menos igual que la de opencv y no valía la pena.

https://github.com/deepakcrk/yolov5-crowdhuman/tree/master
Esta se quedó como otra opción, ya que había que entrenarla por uno mismo usando datasets públicos.

La librería con la que me he quedado es realmente un paquete de ROS Noetic. Pero investigando en el src de este paquete he visto que está todo muy bien organizado y que con un simple script de python, cambiar algunas dependencias y código se puede adaptar a algo que se ejecute con python3 detector.py y ya funciona.
Además está tan bien organizado que me ha dado ya un poco medio hecho como estructurar lo que será parte de la plantilla que usará el usuario y qué parte será la que tenga que programar. 
Link: https://github.com/khayliang/person_tracking_ros

Ya lo he metido dentro del docker pero no puedo poner imágenes porque estoy teniendo problemas el showImage en el GUI, pero parece que funciona perfecto viendo la consola.
Ahora con la percepción solucionada. Falta adaptar un poco las funciones para que sean una plantilla de Unibotics y tendría la parte perceptiva de la solución, quedando solo la actuadora.
